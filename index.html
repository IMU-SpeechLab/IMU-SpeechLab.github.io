<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>IMU-SpeechLab</title>
  <link rel="preconnect" href="https://fonts.googleapis.com" />
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Space+Grotesk:wght@400;500;600;700&family=Noto+Sans+SC:wght@300;400;500;600&display=swap" />
  <link rel="stylesheet" href="styles.css" />
</head>
<body data-lang="zh">
  <header class="site-header">
    <div class="brand">
      <div class="brand-logo">
        <img src="imu-logo.png" alt="IMU logo" />
      </div>
      <div class="brand-text">
        <div class="brand-title">IMU-SpeechLab</div>
        <div class="brand-sub">
          <span class="lang-zh">å†…è’™å¤å¤§å­¦ è®¡ç®—æœºå­¦é™¢ è¯­éŸ³å®éªŒå®¤</span>
          <span class="lang-en">Speech Lab, School of Computer Science, Inner Mongolia University</span>
        </div>
      </div>
    </div>
    <nav class="nav-tabs" role="tablist" aria-label="Primary">
      <button class="tab-btn is-active" type="button" data-tab="home" role="tab" aria-controls="home" aria-selected="true">
        <span class="lang-zh">é¦–é¡µ</span>
        <span class="lang-en">Home</span>
      </button>
      <button class="tab-btn" type="button" data-tab="publications" role="tab" aria-controls="publications" aria-selected="false">
        <span class="lang-zh">è®ºæ–‡</span>
        <span class="lang-en">Publications</span>
      </button>
      <button class="tab-btn" type="button" data-tab="members" role="tab" aria-controls="members" aria-selected="false">
        <span class="lang-zh">æˆå‘˜</span>
        <span class="lang-en">Members</span>
      </button>
    </nav>
    <div class="lang-switch" aria-label="Language">
      <button class="lang-btn is-active" type="button" data-lang="zh" aria-pressed="true">ä¸­æ–‡</button>
      <button class="lang-btn" type="button" data-lang="en" aria-pressed="false">EN</button>
    </div>
  </header>

  <main>
    <section id="home" class="tab-panel is-active" role="tabpanel">
      <div class="hero">
        <div class="hero-text" data-animate>
          <div class="eyebrow">IMU-SpeechLab</div>
          <h1>
            <span class="lang-zh">è®©ä¸–ç•Œæ›´å®‰é™</span>
            <span class="lang-en">Make the World Quieter</span>
          </h1>
          <p class="lead lang-zh">IMU-SpeechLab æ˜¯å†…è’™å¤å¤§å­¦ï¼ˆIMUï¼‰è®¡ç®—æœºå­¦é™¢å¼ å­¦è‰¯æ•™æˆé¢†å¯¼çš„è¯­éŸ³å®éªŒå®¤ï¼Œèšç„¦è¯­éŸ³ä¸éŸ³é¢‘ä¿¡å·å¤„ç†åŠç›¸å…³äººå·¥æ™ºèƒ½é—®é¢˜ç ”ç©¶ã€‚æˆ‘ä»¬æ—¨åœ¨æ„å»ºèƒ½å¤Ÿåœ¨å¤æ‚å£°å­¦ç¯å¢ƒä¸­ç¨³å¥æ„ŸçŸ¥ä¸ç†è§£è¯­éŸ³å’ŒéŸ³é¢‘çš„æœºå™¨è†å¬ç³»ç»Ÿï¼Œé‡ç‚¹å…³æ³¨æ··å“æ¡ä»¶ä¸‹ã€å¤šè¯´è¯äººå¹¶å‘ä¸é‡å è¯­éŸ³ç­‰å…¸å‹æŒ‘æˆ˜ã€‚å½“å‰ç ”ç©¶æ–¹å‘åŒ…æ‹¬ä½†ä¸é™äºè¯­éŸ³å¢å¼ºã€è¯´è¯äººåˆ†ç¦»ã€ç›®æ ‡è¯´è¯äººæå–ã€è¯­éŸ³å»æ··å“ã€ä¸»åŠ¨é™å™ªç­‰ï¼Œè‡´åŠ›äºæ¨åŠ¨ç›¸å…³è¯­éŸ³ç®—æ³•åœ¨çœŸå®åœºæ™¯ä¸­çš„ç¨³å¥åº”ç”¨ã€‚</p>
          <p class="lead lang-en">IMU-SpeechLab is a speech laboratory led by Professor Xueliang Zhang at the School of Computer Science, Inner Mongolia University (IMU). The lab focuses on research in speech and audio signal processing and related artificial intelligence problems. We aim to build machine listening systems capable of robustly perceiving and understanding speech and audio in complex acoustic environments, with particular emphasis on typical challenges such as reverberant conditions, multi-speaker concurrency, and overlapping speech. Our current research directions include, but are not limited to, speech enhancement, speaker separation, target speaker extraction, speech dereverberation, and active noise control, with the goal of advancing the robust deployment of speech algorithms in real-world scenarios.</p>
          <div class="chip-row">
            <span class="chip">Speech Enhancement</span>
            <span class="chip">Speaker Separation</span>
            <span class="chip">Dereverberation</span>
            <span class="chip">Target Speaker Extraction</span>
            <span class="chip">Robust ASR</span>
          </div>
        </div>
      </div>

      <div class="home-grid">
        <section class="panel" data-animate>
          <h2>
            <span class="lang-zh">åŠ å…¥æˆ‘ä»¬</span>
            <span class="lang-en">Join Us</span>
          </h2>
          <ul class="recruit-list">
            <li>
              <span class="lang-zh">å¼ å­¦è‰¯è€å¸ˆæ¯å¹´é¢„è®¡æ‹›æ”¶<span class="highlight">åšå£«ç ”ç©¶ç”Ÿ1å</span>ï¼Œ<span class="highlight">å­¦æœ¯å‹ç¡•å£«ç ”ç©¶ç”Ÿ2å</span>å’Œ<span class="highlight">ä¸“ä¸šå­¦ä½ç¡•å£«ç ”ç©¶ç”Ÿ2å</span>ã€‚</span>
              <span class="lang-en">Prof. Xueliang Zhang expects to recruit <span class="highlight">1 PhD student</span>, <span class="highlight">2 academic master's students</span>, and <span class="highlight">2 professional master's students</span> each year.</span>
            </li>
            <li>
              <span class="lang-zh">å¼ æ™–è€å¸ˆæ¯å¹´é¢„è®¡æ‹›æ”¶<span class="highlight">å­¦æœ¯å‹ç¡•å£«ç ”ç©¶ç”Ÿ3å</span>å’Œ<span class="highlight">ä¸“ä¸šå­¦ä½ç¡•å£«ç ”ç©¶ç”Ÿ3å</span>ã€‚</span>
              <span class="lang-en">Assoc. Prof. Hui Zhang expects to recruit <span class="highlight">3 academic master's students</span> and <span class="highlight">3 professional master's students</span> each year.</span>
            </li>
            <li>
              <span class="lang-zh">æ½˜ä½³æ…§è€å¸ˆæ¯å¹´é¢„è®¡æ‹›æ”¶<span class="highlight">å­¦æœ¯å‹ç¡•å£«ç ”ç©¶ç”Ÿ3å</span>å’Œ<span class="highlight">ä¸“ä¸šå­¦ä½ç¡•å£«ç ”ç©¶ç”Ÿ3å</span>ã€‚</span>
              <span class="lang-en">Lecturer Jiahui Pan expects to recruit <span class="highlight">3 academic master's students</span> and <span class="highlight">3 professional master's students</span> each year.</span>
            </li>
            <li>
              <span class="lang-zh">å¦‚æœæ‚¨æœ‰å…´è¶£åŠ å…¥æˆ‘ä»¬ï¼Œè¯·å°†æ‚¨çš„<span class="highlight">ç®€å†</span>å‘é€è‡³ä»¥ä¸‹<span class="highlight">é‚®ç®±</span>ï¼š</span>
              <span class="lang-en">If you are interested, please send your <span class="highlight">CV</span> to the following <span class="highlight">emails</span>:</span>
              <div class="email-list">
                <div class="email-item">
                  <span class="lang-zh">å¼ å­¦è‰¯æ•™æˆ</span>
                  <span class="lang-en">Prof. Xueliang Zhang</span>
                  <a class="highlight" href="mailto:cszxl@imu.edu.cn">cszxl@imu.edu.cn</a>
                </div>
                <div class="email-item">
                  <span class="lang-zh">å¼ æ™–æ•™æˆ</span>
                  <span class="lang-en">Prof. Hui Zhang</span>
                  <a class="highlight" href="mailto:cszh@imu.edu.cn">cszh@imu.edu.cn</a>
                </div>
                <div class="email-item">
                  <span class="lang-zh">æ½˜ä½³æ…§è€å¸ˆ</span>
                  <span class="lang-en">Lecturer Jiahui Pan</span>
                  <a class="highlight" href="mailto:cspjh@imu.edu.cn">cspjh@imu.edu.cn</a>
                </div>
              </div>
            </li>
            <li>
              <span class="lang-zh">åŒæ—¶ä¹Ÿæ¬¢è¿ä¼˜ç§€æœ¬ç§‘ç”Ÿè¿›è¡Œç§‘ç ”è®­ç»ƒã€‚</span>
              <span class="lang-en">Outstanding undergraduates are also welcome to join for research training.</span>
            </li>
          </ul>
        </section>

        <section class="panel" data-animate>
          <h2>
            <span class="lang-zh">æ–°é—»</span>
            <span class="lang-en">News</span>
          </h2>
          <ul class="news-list">
            <li class="news-item">
              <span class="news-date">2026.01</span>
              <div class="news-entries">
                <div class="news-entry">
                  <span class="lang-zh">ğŸ‰ğŸ‰ <a href="https://arxiv.org/abs/2505.22229" target="_blank" rel="noopener noreferrer">ã€ŠTwo-stage Audio-Visual Target Speaker Extraction System for Real-Time Processing On Edge Deviceã€‹</a>è¢«è¯­éŸ³é¢†åŸŸæ——èˆ°ä¼šè®® ICASSP 2026 æ¥æ”¶</span>
                  <span class="lang-en">ğŸ‰ğŸ‰ <a href="https://arxiv.org/abs/2505.22229" target="_blank" rel="noopener noreferrer">Two-stage Audio-Visual Target Speaker Extraction System for Real-Time Processing On Edge Device</a> accepted by ICASSP 2026.</span>
                </div>
                <div class="news-entry">
                  <span class="lang-zh">ğŸ‰ğŸ‰ ã€ŠLExTra: Folded Prompt and Split-Role Attention for Target Speaker Extractionã€‹è¢«è¯­éŸ³é¢†åŸŸæ——èˆ°ä¼šè®® ICASSP 2026 æ¥æ”¶</span>
                  <span class="lang-en">ğŸ‰ğŸ‰ LExTra: Folded Prompt and Split-Role Attention for Target Speaker Extraction accepted by ICASSP 2026.</span>
                </div>
              </div>
            </li>
            <li class="news-item">
              <span class="news-date">2025.11</span>
              <div class="news-entries">
                <div class="news-entry">
                  <span class="lang-zh">ğŸ‰ğŸ‰ <a href="https://arxiv.org/abs/2505.05114" target="_blank" rel="noopener noreferrer">ã€ŠListen to Extract: Onset-Prompted Target Speaker Extractionã€‹</a>è¢«è¯­éŸ³é¢†åŸŸæ——èˆ°æœŸåˆŠ Transactions on Audio, Speech and Language Processing æ¥æ”¶</span>
                  <span class="lang-en">ğŸ‰ğŸ‰ <a href="https://arxiv.org/abs/2505.05114" target="_blank" rel="noopener noreferrer">Listen to Extract: Onset-Prompted Target Speaker Extraction</a> accepted by Transactions on Audio, Speech and Language Processing (TASLP).</span>
                </div>
              </div>
            </li>
            <li class="news-item">
              <span class="news-date">2025.8</span>
              <div class="news-entries">
                <div class="news-entry">
                  <span class="lang-zh">ğŸ‰ğŸ‰ <a href="https://www.sciencedirect.com/science/article/abs/pii/S0893608025002679" target="_blank" rel="noopener noreferrer">ã€ŠEnhancing target speaker extraction with Hierarchical Speaker Representation Learningã€‹</a>è¢«æœŸåˆŠ Neural Networks æ¥æ”¶</span>
                  <span class="lang-en">ğŸ‰ğŸ‰ <a href="https://www.sciencedirect.com/science/article/abs/pii/S0893608025002679" target="_blank" rel="noopener noreferrer">Enhancing target speaker extraction with Hierarchical Speaker Representation Learning</a> accepted by Neural Networks.</span>
                </div>
                <div class="news-entry">
                  <span class="lang-zh">ğŸ§©ğŸ§© å®éªŒå®¤å›¢é˜Ÿèµ´è·å…°é¹¿ç‰¹ä¸¹å‚åŠ  Interspeech 2025</span>
                  <span class="lang-en">ğŸ§©ğŸ§© The lab team attended Interspeech 2025 in Rotterdam, the Netherlands.</span>
                </div>
              </div>
            </li>
            <li class="news-item">
              <span class="news-date">2025.5</span>
              <div class="news-entries">
                <div class="news-entry">
                  <span class="lang-zh">ğŸ‰ğŸ‰ <a href="https://www.isca-archive.org/interspeech_2025/liu25d_interspeech.pdf" target="_blank" rel="noopener noreferrer">ã€ŠHWB-Net: A Novel High-Performance and Efficient Hybrid Waveform Bandwidth Extension Methodã€‹</a>è¢«è¯­éŸ³é¢†åŸŸæ——èˆ°ä¼šè®® Interspeech 2025 æ¥æ”¶</span>
                  <span class="lang-en">ğŸ‰ğŸ‰ <a href="https://www.isca-archive.org/interspeech_2025/liu25d_interspeech.pdf" target="_blank" rel="noopener noreferrer">HWB-Net: A Novel High-Performance and Efficient Hybrid Waveform Bandwidth Extension Method</a> accepted by Interspeech 2025.</span>
                </div>
                <div class="news-entry">
                  <span class="lang-zh">ğŸ‰ğŸ‰ <a href="https://www.isca-archive.org/interspeech_2025/bao25_interspeech.pdf" target="_blank" rel="noopener noreferrer">ã€ŠFrequency-Domain Enhanced Extreme Bandwidth Extension Network with ICCRN for Superior Speech Qualityã€‹</a>è¢«è¯­éŸ³é¢†åŸŸæ——èˆ°ä¼šè®® Interspeech 2025 æ¥æ”¶</span>
                  <span class="lang-en">ğŸ‰ğŸ‰ <a href="https://www.isca-archive.org/interspeech_2025/bao25_interspeech.pdf" target="_blank" rel="noopener noreferrer">Frequency-Domain Enhanced Extreme Bandwidth Extension Network with ICCRN for Superior Speech Quality</a> accepted by Interspeech 2025.</span>
                </div>
                <div class="news-entry">
                  <span class="lang-zh">ğŸ‰ğŸ‰ <a href="https://www.isca-archive.org/interspeech_2025/li25d_interspeech.pdf" target="_blank" rel="noopener noreferrer">ã€ŠTF-SkiMNet: Speech Enhancement Based on Inplace Modeling and Skipping Memory in Time-Frequency Domainã€‹</a>è¢«è¯­éŸ³é¢†åŸŸæ——èˆ°ä¼šè®® Interspeech 2025 æ¥æ”¶</span>
                  <span class="lang-en">ğŸ‰ğŸ‰ <a href="https://www.isca-archive.org/interspeech_2025/li25d_interspeech.pdf" target="_blank" rel="noopener noreferrer">TF-SkiMNet: Speech Enhancement Based on Inplace Modeling and Skipping Memory in Time-Frequency Domain</a> accepted by Interspeech 2025.</span>
                </div>
                <div class="news-entry">
                  <span class="lang-zh">ğŸ‰ğŸ‰ <a href="https://www.isca-archive.org/interspeech_2025/shen25_interspeech.pdf" target="_blank" rel="noopener noreferrer">ã€ŠARiSE: Auto-Regressive Multi-Channel Speech Enhancementã€‹</a>è¢«è¯­éŸ³é¢†åŸŸæ——èˆ°ä¼šè®® Interspeech 2025 æ¥æ”¶</span>
                  <span class="lang-en">ğŸ‰ğŸ‰ <a href="https://www.isca-archive.org/interspeech_2025/shen25_interspeech.pdf" target="_blank" rel="noopener noreferrer">ARiSE: Auto-Regressive Multi-Channel Speech Enhancement</a> accepted by Interspeech 2025.</span>
                </div>
                <div class="news-entry">
                  <span class="lang-zh">ğŸ‰ğŸ‰ <a href="https://www.isca-archive.org/interspeech_2025/zhao25e_interspeech.pdf" target="_blank" rel="noopener noreferrer">ã€ŠMulti-Channel Acoustic Echo Cancellation Based on Direction-of-Arrival Estimationã€‹</a>è¢«è¯­éŸ³é¢†åŸŸæ——èˆ°ä¼šè®® Interspeech 2025 æ¥æ”¶</span>
                  <span class="lang-en">ğŸ‰ğŸ‰ <a href="https://www.isca-archive.org/interspeech_2025/zhao25e_interspeech.pdf" target="_blank" rel="noopener noreferrer">Multi-Channel Acoustic Echo Cancellation Based on Direction-of-Arrival Estimation</a> accepted by Interspeech 2025.</span>
                </div>
                <div class="news-entry">
                  <span class="lang-zh">ğŸ‰ğŸ‰ <a href="https://www.isca-archive.org/interspeech_2025/zhao25b_interspeech.pdf" target="_blank" rel="noopener noreferrer">ã€ŠRoom Impulse Response as a Prompt for Acoustic Echo Cancellationã€‹</a>è¢«è¯­éŸ³é¢†åŸŸæ——èˆ°ä¼šè®® Interspeech 2025 æ¥æ”¶</span>
                  <span class="lang-en">ğŸ‰ğŸ‰ <a href="https://www.isca-archive.org/interspeech_2025/zhao25b_interspeech.pdf" target="_blank" rel="noopener noreferrer">Room Impulse Response as a Prompt for Acoustic Echo Cancellation</a> accepted by Interspeech 2025.</span>
                </div>
              </div>
            </li>
          </ul>
        </section>
      </div>
    </section>

    <section id="publications" class="tab-panel" role="tabpanel">
      <div class="section-header" data-animate>
        <h2>
          <span class="lang-zh">è®ºæ–‡</span>
          <span class="lang-en">Publications</span>
        </h2>
        <!-- <p class="section-sub">
          <span class="lang-zh">è®ºæ–‡åˆ—è¡¨ä» pub.pdf è‡ªåŠ¨æ•´ç†ï¼Œå»ºè®®æ ¸å¯¹åæŒç»­æ›´æ–°ã€‚</span>
          <span class="lang-en">Publications are parsed from pub.pdf; please review and update as needed.</span>
        </p> -->
      </div>

      <div class="pub-toolbar" data-animate>
        <input id="pub-search" class="pub-search" type="search" placeholder="æœç´¢æ ‡é¢˜ã€ä½œè€…æˆ–æœŸåˆŠ/ä¼šè®®" />
        <select id="pub-year" class="pub-year"></select>
        <div id="pub-count" class="pub-count"></div>
      </div>
      <div id="pub-empty" class="empty-state" hidden></div>
      <div id="pub-list" class="pub-list"></div>
    </section>

    <section id="members" class="tab-panel" role="tabpanel">
      <div class="section-header" data-animate>
        <h2>
          <span class="lang-zh">æˆå‘˜</span>
          <span class="lang-en">Members</span>
        </h2>
        <!-- <p class="section-sub">
          <span class="lang-zh">æ•™å¸ˆä¿¡æ¯å®Œæ•´å±•ç¤ºï¼›å­¦ç”Ÿä¸æ ¡å‹å¯æŒ‰éœ€è¡¥å……ã€‚</span>
          <span class="lang-en">Faculty are listed in full. Student and alumni lists can be completed as needed.</span>
        </p> -->
      </div>

      <section class="member-section" data-animate>
        <h3>
          <span class="lang-zh">æ•™å¸ˆ</span>
          <span class="lang-en">Faculty</span>
        </h3>
        <div id="faculty-list" class="card-grid"></div>
      </section>

      <section class="member-section" data-animate>
        <h3>
          <span class="lang-zh">åœ¨è¯»å­¦ç”Ÿ</span>
          <span class="lang-en">Current Students</span>
        </h3>
        <div id="students-list" class="year-groups"></div>
        <div id="students-empty" class="empty-state" hidden></div>
      </section>

      <section class="member-section" data-animate>
        <h3>
          <span class="lang-zh">æ ¡å‹</span>
          <span class="lang-en">Alumni</span>
        </h3>
        <div id="alumni-list" class="year-groups"></div>
        <div id="alumni-empty" class="empty-state" hidden></div>
      </section>
    </section>
  </main>

  <footer class="site-footer">
    <span class="lang-zh">IMU-SpeechLab</span>
    <span class="lang-en">IMU-SpeechLab</span>
  </footer>

  <script src="data/publications.js"></script>
  <script src="data/members.js"></script>
  <script src="script.js"></script>
</body>
</html>
